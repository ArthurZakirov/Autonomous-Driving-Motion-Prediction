import sys
import os
import argparse
import evaluate_MemNet

sys.path.append('../train/trainer')
from load_data import load_data_from_env


def parse_config():
    parser = argparse.ArgumentParser()
    parser.add_argument("--cuda", default=False)
    parser.add_argument("--batch_size", type=int, default=32)
    parser.add_argument("--past_len", type=int, default=20)
    parser.add_argument("--future_len", type=int, default=60)
    parser.add_argument("--preds", type=int, default=10, help="k best predictions")
    parser.add_argument("--dim_clip", type=int, default=180,
                        help="total size of the map window around the vehicle (in pixels)")

    parser.add_argument("--metrics", type=str, default='nuScenes_competition', help= 'Evaluation metrics: "nuScenes-competition" / "MANTRA_paper" ')
    parser.add_argument("--model", type=str, default='pretrained_models/MANTRA/model_MANTRA')
    parser.add_argument("--visualize_dataset", default=False)
    parser.add_argument("--saved_memory", default=True)
    parser.add_argument("--memories_path", default='pretrained_models/MANTRA/memories/')
    parser.add_argument("--withIRM", default=True, help='generate predictions with/without IRM')
    parser.add_argument("--saveImages", default='None',
                        help=
                        '''
                        Save in test folder examples of dataset with predictions generated by MANTRA.
                        If None, it does not save anything.
                        If 'All', it saves all examples.
                        If 'Subset', it saves examples defined in index_qualitative.py (handpicked significant samples)
                        ''')

    parser.add_argument("--dataset_file_train", type=str, default="Kitti/kitti_train_title.json",
                        help="dataset file with training samples")
    parser.add_argument("--dataset_file_eval", type=str, default="Kitti/kitti_val_title.json",
                        help="dataset file with evaluation samples")
    parser.add_argument("--info", type=str, default='', help='Name of evaluation. '
                                                             'It will use for name of the test folder.')
    return parser.parse_args()


def main(config):
    v = evaluate_MemNet.Validator(config)
    print('start evaluation')
    v.test_model()


if __name__ == "__main__":
    #python test.py --model "training/training_IRM/lyft_middle_train_2021-09-17 20:24/model" --dataset_file_train Kitti/kitti_sample_title.json --dataset_file_eval Kitti/kitti_sample_title.json
    config = parse_config()
    main(config)
